{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parser\n",
    "Format the output to post-processing the data, example: receive data from LLM and use in the system, after that return to the user.\n",
    "\n",
    "The parsers padronize the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting response to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "client_review = \"\"\"This leaf blower is pretty awesome. It has four settings: candle blow, gentle breeze, \n",
    "windy city, and tornado. It arrived in two days, just in time for my wife's birthday present. I think my \n",
    "wife loved it so much she was speechless. So far, I've been the only one using it, and I've been using it \n",
    "every other morning to clear the leaves from our lawn. It's a little more expensive than other leaf blowers \n",
    "on the market, but I think it's worth it for the extra features.\"\"\"\n",
    "\n",
    "present_schema = ResponseSchema(\n",
    "    name='is_present',\n",
    "    type='boolean',\n",
    "    description='Whether the product is a present or gift.'\n",
    ")\n",
    "\n",
    "schema_delivery = ResponseSchema(\n",
    "    name='delivery_days',\n",
    "    type='int',\n",
    "    description='Number of days it took for the product to be delivered.'\n",
    ")\n",
    "\n",
    "perception_value = ResponseSchema(\n",
    "    name='perception_value',\n",
    "    type='list',\n",
    "    description='Extract any phrase about the perception of value about the product. Return as a Python list.'\n",
    ")\n",
    "\n",
    "response_schema = [present_schema, schema_delivery, perception_value]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "\n",
    "schema_format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"is_present\": true,\n",
      "\t\"delivery_days\": 2,\n",
      "\t\"perception_value\": [\"I think it's worth it for the extra features\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "review_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "Given the text, extract the following information:                                                   \n",
    "\n",
    "is_present, delivery_days and perception_value\n",
    "\n",
    "Text: {review}\n",
    "\n",
    "{schema}\n",
    "\n",
    "\"\"\", partial_variables={'schema': schema_format_instructions})\n",
    "\n",
    "prompt = review_template.format_messages(review=client_review)\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting response to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "json_response = output_parser.parse(response.content)\n",
    "\n",
    "print(json_response['is_present'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
