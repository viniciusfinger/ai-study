{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation\n",
    "A technique to augment the generation of LLMs retrieveling data from external sources, like web, csv, wikipedia, google, notion...\n",
    "\n",
    "Os modelos de LLM tem uma limitação de entrada, então não basta simplesmente colar, por exemplo, o PDF no prompt e pedir a informação. \n",
    "\n",
    "O RAG buscará dentro dos dados que foram inputados (PDFs, por exemplo) e buscar trechos que estejam relacionados a busca. Esses trechos serão passados ao prompt e então o LLM conseguirá responder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo a passo\n",
    "1. Document loading: carrega o dado para o computador/disco/nuvem\n",
    "2. Document Splitting: quebra esse dado em diversos trechos, existem diversas técnias para isso.\n",
    "3. Embedding: transformar as quebras em um array de floats, tornando mais fácil de comparar qual texto é mais parecido com o que o usuário deseja saber.\n",
    "4. Armazenagem: Armazena os vetores gerados no processo 3 em um vector store.\n",
    "5. Retrieval: Busca por dados dentro da vector store a partir da pergunta do usuário também embedada, comparando e trazendo o dado mais próximo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
